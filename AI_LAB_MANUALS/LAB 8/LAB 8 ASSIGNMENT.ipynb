{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28403e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Import libraries and define dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09623274",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = \"\"\"About the Program\n",
    "What is the course fee for Data Science Mentorship Program (DSMP 2023)\n",
    "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
    "... (rest of faqs text) ...\n",
    "Discussion on Job hunting strategies\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0159be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e122a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sentence in text_data.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1, len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])\n",
    "\n",
    "max_len = max([len(x) for x in input_sequences])\n",
    "padded_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')\n",
    "\n",
    "X = padded_sequences[:, :-1]\n",
    "y = to_categorical(padded_sequences[:, -1], num_classes=len(tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29f91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b69fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\University\\Semster 5\\AI Lab\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_len-1))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7348faac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">180,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,587</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m3,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m180,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │         \u001b[38;5;34m5,587\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">340,487</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m340,487\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">340,487</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m340,487\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, max_len-1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bd65fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 4s - 2s/step - accuracy: 0.0541 - loss: 3.6121\n",
      "Epoch 2/100\n",
      "2/2 - 0s - 52ms/step - accuracy: 0.0811 - loss: 3.5971\n",
      "Epoch 3/100\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.0811 - loss: 3.5856\n",
      "Epoch 4/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.0811 - loss: 3.5698\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.0541 - loss: 3.5454\n",
      "Epoch 6/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.0541 - loss: 3.5059\n",
      "Epoch 7/100\n",
      "2/2 - 0s - 57ms/step - accuracy: 0.0541 - loss: 3.4498\n",
      "Epoch 8/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.0541 - loss: 3.4110\n",
      "Epoch 9/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.0541 - loss: 3.4219\n",
      "Epoch 10/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.0541 - loss: 3.3788\n",
      "Epoch 11/100\n",
      "2/2 - 0s - 57ms/step - accuracy: 0.1081 - loss: 3.3216\n",
      "Epoch 12/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.1351 - loss: 3.2855\n",
      "Epoch 13/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.1622 - loss: 3.2608\n",
      "Epoch 14/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.1622 - loss: 3.2162\n",
      "Epoch 15/100\n",
      "2/2 - 0s - 54ms/step - accuracy: 0.1351 - loss: 3.1749\n",
      "Epoch 16/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.1351 - loss: 3.1290\n",
      "Epoch 17/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.1351 - loss: 3.0469\n",
      "Epoch 18/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.1622 - loss: 2.9632\n",
      "Epoch 19/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.1622 - loss: 2.9156\n",
      "Epoch 20/100\n",
      "2/2 - 0s - 55ms/step - accuracy: 0.1622 - loss: 2.8536\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.1622 - loss: 2.8147\n",
      "Epoch 22/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.1892 - loss: 2.7703\n",
      "Epoch 23/100\n",
      "2/2 - 0s - 54ms/step - accuracy: 0.1622 - loss: 2.7387\n",
      "Epoch 24/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.2162 - loss: 2.6486\n",
      "Epoch 25/100\n",
      "2/2 - 0s - 76ms/step - accuracy: 0.1351 - loss: 2.5946\n",
      "Epoch 26/100\n",
      "2/2 - 0s - 110ms/step - accuracy: 0.2432 - loss: 2.5486\n",
      "Epoch 27/100\n",
      "2/2 - 0s - 93ms/step - accuracy: 0.2432 - loss: 2.4813\n",
      "Epoch 28/100\n",
      "2/2 - 0s - 171ms/step - accuracy: 0.1622 - loss: 2.4804\n",
      "Epoch 29/100\n",
      "2/2 - 0s - 77ms/step - accuracy: 0.2432 - loss: 2.4007\n",
      "Epoch 30/100\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.2162 - loss: 2.3545\n",
      "Epoch 31/100\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3243 - loss: 2.2996\n",
      "Epoch 32/100\n",
      "2/2 - 0s - 75ms/step - accuracy: 0.3243 - loss: 2.2715\n",
      "Epoch 33/100\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3243 - loss: 2.2440\n",
      "Epoch 34/100\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.2703 - loss: 2.2211\n",
      "Epoch 35/100\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.2162 - loss: 2.1911\n",
      "Epoch 36/100\n",
      "2/2 - 0s - 94ms/step - accuracy: 0.3243 - loss: 2.1236\n",
      "Epoch 37/100\n",
      "2/2 - 0s - 83ms/step - accuracy: 0.3784 - loss: 2.0917\n",
      "Epoch 38/100\n",
      "2/2 - 0s - 81ms/step - accuracy: 0.3243 - loss: 2.0517\n",
      "Epoch 39/100\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.3514 - loss: 2.0114\n",
      "Epoch 40/100\n",
      "2/2 - 0s - 82ms/step - accuracy: 0.3243 - loss: 1.9629\n",
      "Epoch 41/100\n",
      "2/2 - 0s - 79ms/step - accuracy: 0.3243 - loss: 1.9412\n",
      "Epoch 42/100\n",
      "2/2 - 0s - 68ms/step - accuracy: 0.4054 - loss: 1.9239\n",
      "Epoch 43/100\n",
      "2/2 - 0s - 72ms/step - accuracy: 0.4595 - loss: 1.8982\n",
      "Epoch 44/100\n",
      "2/2 - 0s - 70ms/step - accuracy: 0.4054 - loss: 1.8628\n",
      "Epoch 45/100\n",
      "2/2 - 0s - 68ms/step - accuracy: 0.3784 - loss: 1.8566\n",
      "Epoch 46/100\n",
      "2/2 - 0s - 66ms/step - accuracy: 0.4324 - loss: 1.8191\n",
      "Epoch 47/100\n",
      "2/2 - 0s - 58ms/step - accuracy: 0.4054 - loss: 1.8298\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 55ms/step - accuracy: 0.4324 - loss: 1.7852\n",
      "Epoch 49/100\n",
      "2/2 - 0s - 56ms/step - accuracy: 0.4054 - loss: 1.7430\n",
      "Epoch 50/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.5946 - loss: 1.6944\n",
      "Epoch 51/100\n",
      "2/2 - 0s - 56ms/step - accuracy: 0.5946 - loss: 1.6919\n",
      "Epoch 52/100\n",
      "2/2 - 0s - 54ms/step - accuracy: 0.4324 - loss: 1.6707\n",
      "Epoch 53/100\n",
      "2/2 - 0s - 52ms/step - accuracy: 0.5676 - loss: 1.6080\n",
      "Epoch 54/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.2973 - loss: 1.7653\n",
      "Epoch 55/100\n",
      "2/2 - 0s - 52ms/step - accuracy: 0.5676 - loss: 1.6243\n",
      "Epoch 56/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.4054 - loss: 1.6496\n",
      "Epoch 57/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.4595 - loss: 1.5940\n",
      "Epoch 58/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.5135 - loss: 1.5714\n",
      "Epoch 59/100\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.5405 - loss: 1.5404\n",
      "Epoch 60/100\n",
      "2/2 - 0s - 54ms/step - accuracy: 0.5135 - loss: 1.5356\n",
      "Epoch 61/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.5946 - loss: 1.4776\n",
      "Epoch 62/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.5405 - loss: 1.5227\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.6216 - loss: 1.4600\n",
      "Epoch 64/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.5676 - loss: 1.4529\n",
      "Epoch 65/100\n",
      "2/2 - 0s - 52ms/step - accuracy: 0.5405 - loss: 1.4303\n",
      "Epoch 66/100\n",
      "2/2 - 0s - 56ms/step - accuracy: 0.5676 - loss: 1.4324\n",
      "Epoch 67/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.5135 - loss: 1.4263\n",
      "Epoch 68/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.5946 - loss: 1.3813\n",
      "Epoch 69/100\n",
      "2/2 - 0s - 54ms/step - accuracy: 0.5676 - loss: 1.3622\n",
      "Epoch 70/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.6757 - loss: 1.3582\n",
      "Epoch 71/100\n",
      "2/2 - 0s - 55ms/step - accuracy: 0.5676 - loss: 1.3453\n",
      "Epoch 72/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.5946 - loss: 1.3148\n",
      "Epoch 73/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.6216 - loss: 1.3017\n",
      "Epoch 74/100\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.5946 - loss: 1.2697\n",
      "Epoch 75/100\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.6486 - loss: 1.2498\n",
      "Epoch 76/100\n",
      "2/2 - 0s - 56ms/step - accuracy: 0.6486 - loss: 1.2367\n",
      "Epoch 77/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.6216 - loss: 1.2375\n",
      "Epoch 78/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.6216 - loss: 1.2169\n",
      "Epoch 79/100\n",
      "2/2 - 0s - 52ms/step - accuracy: 0.6486 - loss: 1.1805\n",
      "Epoch 80/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.5946 - loss: 1.2097\n",
      "Epoch 81/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.6486 - loss: 1.1969\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 52ms/step - accuracy: 0.6486 - loss: 1.1885\n",
      "Epoch 83/100\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.7027 - loss: 1.1610\n",
      "Epoch 84/100\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.6757 - loss: 1.1369\n",
      "Epoch 85/100\n",
      "2/2 - 0s - 49ms/step - accuracy: 0.6216 - loss: 1.1404\n",
      "Epoch 86/100\n",
      "2/2 - 0s - 56ms/step - accuracy: 0.7027 - loss: 1.1216\n",
      "Epoch 87/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.6757 - loss: 1.1117\n",
      "Epoch 88/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.6757 - loss: 1.1323\n",
      "Epoch 89/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.7568 - loss: 1.0851\n",
      "Epoch 90/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.7297 - loss: 1.0819\n",
      "Epoch 91/100\n",
      "2/2 - 0s - 55ms/step - accuracy: 0.7568 - loss: 1.0814\n",
      "Epoch 92/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.6757 - loss: 1.1118\n",
      "Epoch 93/100\n",
      "2/2 - 0s - 53ms/step - accuracy: 0.6216 - loss: 1.0850\n",
      "Epoch 94/100\n",
      "2/2 - 0s - 50ms/step - accuracy: 0.7027 - loss: 1.0572\n",
      "Epoch 95/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.6757 - loss: 1.0933\n",
      "Epoch 96/100\n",
      "2/2 - 0s - 55ms/step - accuracy: 0.7027 - loss: 1.0431\n",
      "Epoch 97/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.6757 - loss: 1.0986\n",
      "Epoch 98/100\n",
      "2/2 - 0s - 52ms/step - accuracy: 0.7027 - loss: 1.0430\n",
      "Epoch 99/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.6757 - loss: 1.0577\n",
      "Epoch 100/100\n",
      "2/2 - 0s - 51ms/step - accuracy: 0.6757 - loss: 1.0802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a57399a550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b5e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Next-word prediction for a given input\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2925bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"what is the fee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c9d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "padded_token_text = pad_sequences([token_text], maxlen=max_len-1, padding='pre')\n",
    "\n",
    "predicted_index = np.argmax(model.predict(padded_token_text, verbose=0))\n",
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted_index:\n",
    "        predicted_word = word\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3349511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: 'what is the fee'\n",
      "Next predicted word: 'fee'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input text: '{input_text}'\")\n",
    "print(f\"Next predicted word: '{predicted_word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2307472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 modified. Generate 5 words sequentially\n",
    "input_text = \"what is the fee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0656e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    token_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    padded_token_text = pad_sequences([token_text], maxlen=max_len-1, padding='pre')\n",
    "    \n",
    "    predicted_index = np.argmax(model.predict(padded_token_text, verbose=0))\n",
    "    \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            input_text += \" \" + word\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c86d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: what is the fee fee for data science mentorship\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated text:\", input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
